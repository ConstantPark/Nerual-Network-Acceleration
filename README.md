## Neural Network Acceleration Study
This is a repository of the study "neural network acceleration". The goal of this study is to understand the acceleration of nerual networks on various devices. The topic of acceleration includes `CPU`,`GPU`, `FPGA`, `ASIC` and `PIM`. Our materials are open to this github and youtube.

#### CPU and GPU
- Desinging optimized BLAS for CPU or GPU
- Optimal primitive selection on heterogeneous system architecture (HSA) device
- CUDA/OpenCL kernel design

#### ASIC and FPGA
- Low-power inference acceleration using HLS or RTL design
- High computing performance training accelerator

#### PIM (NDP)
- DIMM and HMC based neural acceleration system
- Non-HBM based design

## Presentation with Video
### Week1: Introduction of NNQ&CND
**Title: A Piece of Weight**  
Presentor: 김정훈 (Jeonghoon Kim)  
PPT: https://drive.google.com/open?id=1RQAiIFX7wOUMiZXPCIZbXb_6DtLlV38e  
Video: https://youtu.be/pohMFz-uQJ0  

## Contributors
**Main Contributor**: Constant Park (https://constantpark.github.io/).  
**Presenter**: Constanr Park, ~
